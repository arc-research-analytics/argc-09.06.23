{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8cd4a15-e7a0-452a-bc39-6ea08024d105",
   "metadata": {},
   "source": [
    "# data source: <a href=\"https://qpublic.schneidercorp.com/Application.aspx?AppID=1027&LayerID=21667&PageTypeID=2&PageID=9280\" style=\"color: #ff9d00; text-decoration: none; font-weight: 600;\">Forsyth County Qpublic</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23952f7-d6a4-4d3e-a074-4478215c626f",
   "metadata": {},
   "source": [
    "# 1) Compile home sales data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720d2a81-0db5-4318-ac45-07d95ec0c8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # allow Python to slither through our file tree\n",
    "import glob # this module will allow use of wildcard characters to find and combine data\n",
    "import pandas as pd # pandas dataframes will hold our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d690cf-1d42-4dac-9a85-68f5007bddb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# navigate to where the CSVs live \n",
    "path = 'Data/Glob/' \n",
    "\n",
    "# create list of all CSV in the variable 'path' above \n",
    "path_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "# concatenate, remove duplicates\n",
    "df = pd.concat((pd.read_csv(f) for f in path_files)).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Describe the dataframe \n",
    "print(f'The combined dataframe has {df.shape[0]:,} rows & {df.shape[1]} columns.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fef32f-ccda-481c-8000-b53425f90695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, show the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4273d982-4449-4bb6-acbb-a4683417d450",
   "metadata": {},
   "source": [
    "# 2) Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec96561-cfdf-4622-8d66-82939e8ff76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unwanted columns\n",
    "df1 = df.drop(columns=[\n",
    "    'Parcel ID',\n",
    "    'Owner Name',\n",
    "    'Owner Address',\n",
    "    'Grantor',\n",
    "    'Grantee',\n",
    "    'Qualified Sales',\n",
    "    'Sales Validity',\n",
    "    'Acres',\n",
    "    'Parcel  Class ',\n",
    "    'Tax District',\n",
    "    'Neighborhood',\n",
    "    'Zoning'\n",
    "])\n",
    "\n",
    "# create the \"full address\" column for Google Maps to read\n",
    "df1['full_address'] = df1['Address'].str.title() + ' Forsyth County GA'\n",
    "df1.head(10)\n",
    "\n",
    "# set the 'space filler', a URL-encoded stand in for a space character\n",
    "space_filler = '%20'\n",
    "\n",
    "# inject the 'space filler' into 'full_address' column\n",
    "df1['full_address'] = df1['full_address'].str.replace(' ', space_filler)\n",
    "pd.set_option('display.max_colwidth', 1000)   # display more of the columns\n",
    "df1.head(10)\n",
    "\n",
    "# creates the URL column for geocoding\n",
    "df1['url'] = ['https://www.google.com/maps/search/' + i for i in df1['full_address']]\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816ea2a1-5f7d-4315-92d0-97e974aae76f",
   "metadata": {},
   "source": [
    "# 3) Geocode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98c2e3e-76c8-467c-b27e-9d63b7e9b591",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep # pause the geocoder between \"hits\"\n",
    "from tqdm import tqdm # give a status bar\n",
    "from selenium import webdriver # automate browsing\n",
    "from selenium.webdriver.chrome.options import Options # run in the background\n",
    "import re # use regex to strip out lat / long values\n",
    "import warnings # suppress SettingWithCopyWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62ba648-30f1-4065-8c16-18e02e8d37fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set selenium options\n",
    "options = Options()\n",
    "options.add_argument(\"--headless=new\")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "# this empty list will hold our results\n",
    "results = []\n",
    "\n",
    "# demo a small subset for the geocoder\n",
    "df1 = df1.head(25)\n",
    "\n",
    "# look at the first URL in the dataframe\n",
    "df1['url'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e78dab-2fc1-40b9-a6c2-958e5893a235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loop which will iterate over each row and grab the resulting URL\n",
    "for ind in tqdm(df1.index, colour='#2171b5', desc='Geocoding Progress'):\n",
    "    try:\n",
    "        driver.get(df1['url'][ind])\n",
    "        sleep(3.7)\n",
    "        url = driver.current_url\n",
    "        results.append(url)\n",
    "    except:\n",
    "        results.append('error')\n",
    "\n",
    "print('Geocoding complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a4fbec-7acd-4d01-b2aa-6dd692003c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize 2 empty lists\n",
    "lats = []\n",
    "longs = []\n",
    "\n",
    "# parse & split the 'results' list \n",
    "for item in range(len(results)):\n",
    "    try:\n",
    "        found = re.search('/@(.+?),17z', results[item]).group(1)\n",
    "        lats.append(found.split(',')[0])\n",
    "        longs.append(found.split(',')[1])\n",
    "    except:\n",
    "        lats.append('error')\n",
    "        longs.append('error')\n",
    "        \n",
    "# now add the parsed & cleaned lat/longs as additional columns to our dataframe\n",
    "df1.loc[:, 'lat'] = lats\n",
    "df1.loc[:,'long'] = longs\n",
    "\n",
    "# remove unwanted columns\n",
    "df1.drop(columns=[\n",
    "    'full_address',\n",
    "    'url'\n",
    "], inplace=True)\n",
    "\n",
    "# view the results\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bdf5ed-dee6-4fe9-9f6b-7f7a861708d0",
   "metadata": {},
   "source": [
    "# 4) Spatial join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8417921-9b6b-4865-9057-c8d337702514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 5 years' worth of Forsyth data\n",
    "forsyth_sales = pd.read_csv('Data/Final/FullSet.csv')\n",
    "forsyth_sales.drop(columns=[\n",
    "    'Unnamed: 0'\n",
    "], inplace=True)\n",
    "\n",
    "# Look at the table data\n",
    "forsyth_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69502450-a8ae-4bc8-9fd0-8d9366a3be20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd # like pandas, but for spatial data\n",
    "\n",
    "# convert the pandas dataframe to a geopandas geodataframe\n",
    "forsyth_sales = gpd.GeoDataFrame(\n",
    "    forsyth_sales, \n",
    "    geometry=gpd.points_from_xy(\n",
    "        forsyth_sales.long, \n",
    "        forsyth_sales.lat\n",
    "    ), \n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# visualize the geocoded home sales\n",
    "forsyth_sales.explore(tiles='CartoDB Positron')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cef952-3ec4-4e3d-8969-abdd69c62739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statewide census tracts from Open Data & Mapping Hub\n",
    "url = \"https://services1.arcgis.com/Ug5xGQbHsD8zuZzM/arcgis/rest/services/ACS_2021_Population/FeatureServer/21/query?where=1%3D1&outFields=*&outSR=4326&f=json\"\n",
    "forsyth_tracts = gpd.read_file(url)\n",
    "\n",
    "# only grab Forsyth County\n",
    "forsyth_tracts = forsyth_tracts[forsyth_tracts['GEOID'].str.startswith('13117')]\n",
    "\n",
    "# we're only intersted in the geometry & tract ID\n",
    "forsyth_tracts = forsyth_tracts[['GEOID', 'geometry']]\n",
    "\n",
    "# take a look at the data (map):\n",
    "forsyth_tracts.explore(tiles='CartoDB Positron')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2187b22-b7db-4f66-a967-80bfaf9b9f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new Geopandas Geodataframe of spatially joined data\n",
    "joined_sales = forsyth_sales.sjoin(forsyth_tracts, predicate=\"within\")\n",
    "\n",
    "# drop other joined field\n",
    "joined_sales = joined_sales.drop(columns='index_right')\n",
    "\n",
    "# take a look at the joined data (map)\n",
    "joined_sales.explore()\n",
    "\n",
    "# # take a look at the joined dat (table)\n",
    "# joined_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b35a4ab-cc5a-42d8-9519-68cc0c592b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert our joined_sales geodataframe to a geometry-less pandas dataframe\n",
    "joined_sales = joined_sales.drop(columns='geometry')\n",
    "\n",
    "# Export to a CSV to be used in our 'app.py' file\n",
    "joined_sales.to_csv('Data/Final/FullSet_joined.csv')\n",
    "\n",
    "print('export complete ðŸ¥³')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "argc-demo",
   "language": "python",
   "name": "argc-demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
